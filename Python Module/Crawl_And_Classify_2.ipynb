{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bddaf2a-1aec-40d6-88d9-7171ba1f134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import pickle\n",
    "import pymysql\n",
    "\n",
    "#뛰어쓰기 수정\n",
    "from pykospacing import Spacing\n",
    "spacing = Spacing()\n",
    "#맞춤법 수정\n",
    "from hanspell import spell_checker\n",
    "\n",
    "import sys\n",
    "import soynlp\n",
    "from soynlp.normalizer import *\n",
    "\n",
    "from krwordrank.word import summarize_with_keywords\n",
    "from krwordrank.word import KRWordRank\n",
    "\n",
    "from gensim.models import FastText\n",
    "FastText_model = FastText.load('Code/FastText_Model')\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab(dicpath='C:/mecab/mecab-ko-dic')\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout, Flatten, Activation,BatchNormalization\n",
    "from tensorflow.keras import Input, Model, layers, optimizers, metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys # 시스템\n",
    "import os  # 시스템\n",
    "\n",
    "\n",
    "# selenium 크롤링\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver import ActionChains as AC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "# 크롬 드라이버\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "# beautifulsoup 크롤링\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# lxml 크롤링\n",
    "import lxml.html\n",
    "\n",
    "# 시간 조절\n",
    "import time\n",
    "\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9549e7a9-462b-4e84-b625-6f3e52b373a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "food = pd.read_csv('D:/Code/Muchine Learning/TensorFlow/Project/store.csv',encoding='utf-8')\n",
    "food = food.reset_index(drop=True)\n",
    "food = food.fillna('')\n",
    "print(food.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c81b261-f5ce-4933-97bd-806a2df2c22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10000\n",
      "10000 20000\n",
      "20000 30000\n",
      "30000 40000\n",
      "40000 50000\n",
      "50000 60000\n",
      "60000 70000\n",
      "70000 80000\n",
      "80000 90000\n",
      "90000 100000\n",
      "100000 110000\n",
      "110000 120000\n",
      "120000 130000\n",
      "130000 140000\n",
      "140000 150000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(food)//10000 + 1):\n",
    "    if i == (len(food)//10000):\n",
    "        store_to_csv = food[i * 10000 : len(food)].reset_index(drop=True)\n",
    "    else:\n",
    "        store_to_csv = food[i * 10000 : i * 10000 + 10000].reset_index(drop=True)\n",
    "    print(i * 10000 , i * 10000 + 10000)\n",
    "    store_name = 'stores_' + str(i) + '.csv'\n",
    "    store_to_csv.to_csv(store_name, encoding = 'utf-8',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de36608-7555-464d-a163-580d7c1e85e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "food = pd.read_csv('D:/Code/Muchine Learning/TensorFlow/Project/stores_1.csv',encoding='utf-8')\n",
    "food = food.reset_index(drop=True)\n",
    "food = food.fillna('')\n",
    "print(food.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a9703f-7838-4c00-810b-14a10cbc0cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>지번주소</th>\n",
       "      <th>도로명주소</th>\n",
       "      <th>사업장명</th>\n",
       "      <th>좌표정보(X)</th>\n",
       "      <th>좌표정보(Y)</th>\n",
       "      <th>업태구분명</th>\n",
       "      <th>category_id</th>\n",
       "      <th>table_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>서울특별시 송파구 거여동 554-3번지</td>\n",
       "      <td>서울특별시 송파구 오금로 478 (거여동)</td>\n",
       "      <td>김밥천국</td>\n",
       "      <td>212493.9123</td>\n",
       "      <td>443538.7679</td>\n",
       "      <td>패스트푸드</td>\n",
       "      <td>etc</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>서울특별시 송파구 오금동 73-10번지</td>\n",
       "      <td>서울특별시 송파구 마천로 146 1층 (오금동)</td>\n",
       "      <td>족발천국</td>\n",
       "      <td>211913.0508</td>\n",
       "      <td>444680.0797</td>\n",
       "      <td>기타</td>\n",
       "      <td>etc</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>서울특별시 송파구 석촌동 177-6번지</td>\n",
       "      <td>서울특별시 송파구 백제고분로39길 16 1층 (석촌동)</td>\n",
       "      <td>술있는 식탁 석촌점</td>\n",
       "      <td>209187.0338</td>\n",
       "      <td>444846.4097</td>\n",
       "      <td>기타</td>\n",
       "      <td>etc</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>서울특별시 송파구 오금동 11번지</td>\n",
       "      <td>서울특별시 송파구 양재대로72길 17 상가1동 1층 101-1호 (오금동 현대백조아파트)</td>\n",
       "      <td>일구칠사'1974'</td>\n",
       "      <td>211358.758</td>\n",
       "      <td>445248.7244</td>\n",
       "      <td>기타</td>\n",
       "      <td>etc</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>서울특별시 송파구 문정동 644</td>\n",
       "      <td>서울특별시 송파구 법원로11길 11 A동 115호 (문정동 문정현대지식산업센터1-1)</td>\n",
       "      <td>앵거스</td>\n",
       "      <td>210398.0</td>\n",
       "      <td>442553.0</td>\n",
       "      <td>기타</td>\n",
       "      <td>etc</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>19996</td>\n",
       "      <td>서울특별시 중구 을지로4가 311-1번지</td>\n",
       "      <td></td>\n",
       "      <td>을지로김밥운동</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>분식</td>\n",
       "      <td>etc</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>19997</td>\n",
       "      <td>서울특별시 중구 신당동 370-51 (지상1층)</td>\n",
       "      <td>서울특별시 중구 다산로 155-1 (신당동(지상1층))</td>\n",
       "      <td>망원동 티라미슈</td>\n",
       "      <td>200992.2667</td>\n",
       "      <td>450601.0412</td>\n",
       "      <td>호프/통닭</td>\n",
       "      <td>etc</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>19998</td>\n",
       "      <td>서울특별시 중구 신당동 145-10번지</td>\n",
       "      <td>서울특별시 중구 퇴계로88길 58-4 지하1층 (신당동)</td>\n",
       "      <td>볼륨</td>\n",
       "      <td>201675.9513</td>\n",
       "      <td>451261.801</td>\n",
       "      <td>까페</td>\n",
       "      <td>etc</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>19999</td>\n",
       "      <td>서울특별시 중구 신당동 131-5번지 (지상1층)</td>\n",
       "      <td>서울특별시 중구 퇴계로84길 17 (신당동(지상1층))</td>\n",
       "      <td>골목길</td>\n",
       "      <td>201628.0898</td>\n",
       "      <td>451407.6249</td>\n",
       "      <td>기타</td>\n",
       "      <td>etc</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>20000</td>\n",
       "      <td>서울특별시 중구 을지로6가 23-26번지 (지상1층)</td>\n",
       "      <td>서울특별시 중구 을지로44길 6 (을지로6가(지상1층))</td>\n",
       "      <td>BBQ치킨앤비어</td>\n",
       "      <td>200505.1071</td>\n",
       "      <td>451510.4215</td>\n",
       "      <td>통닭(치킨)</td>\n",
       "      <td>etc</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                            지번주소  \\\n",
       "0     10001          서울특별시 송파구 거여동 554-3번지    \n",
       "1     10002          서울특별시 송파구 오금동 73-10번지    \n",
       "2     10003          서울특별시 송파구 석촌동 177-6번지    \n",
       "3     10004             서울특별시 송파구 오금동 11번지    \n",
       "4     10005              서울특별시 송파구 문정동 644    \n",
       "...     ...                             ...   \n",
       "9995  19996         서울특별시 중구 을지로4가 311-1번지    \n",
       "9996  19997     서울특별시 중구 신당동 370-51 (지상1층)    \n",
       "9997  19998          서울특별시 중구 신당동 145-10번지    \n",
       "9998  19999    서울특별시 중구 신당동 131-5번지 (지상1층)    \n",
       "9999  20000  서울특별시 중구 을지로6가 23-26번지 (지상1층)    \n",
       "\n",
       "                                                  도로명주소        사업장명  \\\n",
       "0                               서울특별시 송파구 오금로 478 (거여동)        김밥천국   \n",
       "1                            서울특별시 송파구 마천로 146 1층 (오금동)        족발천국   \n",
       "2                        서울특별시 송파구 백제고분로39길 16 1층 (석촌동)  술있는 식탁 석촌점   \n",
       "3     서울특별시 송파구 양재대로72길 17 상가1동 1층 101-1호 (오금동 현대백조아파트)  일구칠사'1974'   \n",
       "4       서울특별시 송파구 법원로11길 11 A동 115호 (문정동 문정현대지식산업센터1-1)         앵거스   \n",
       "...                                                 ...         ...   \n",
       "9995                                                        을지로김밥운동   \n",
       "9996                     서울특별시 중구 다산로 155-1 (신당동(지상1층))    망원동 티라미슈   \n",
       "9997                    서울특별시 중구 퇴계로88길 58-4 지하1층 (신당동)          볼륨   \n",
       "9998                     서울특별시 중구 퇴계로84길 17 (신당동(지상1층))         골목길   \n",
       "9999                    서울특별시 중구 을지로44길 6 (을지로6가(지상1층))    BBQ치킨앤비어   \n",
       "\n",
       "          좌표정보(X)      좌표정보(Y)   업태구분명 category_id table_id  \n",
       "0     212493.9123  443538.7679   패스트푸드         etc     food  \n",
       "1     211913.0508  444680.0797      기타         etc     food  \n",
       "2     209187.0338  444846.4097      기타         etc     food  \n",
       "3      211358.758  445248.7244      기타         etc     food  \n",
       "4        210398.0     442553.0      기타         etc     food  \n",
       "...           ...          ...     ...         ...      ...  \n",
       "9995                                분식         etc     food  \n",
       "9996  200992.2667  450601.0412   호프/통닭         etc     food  \n",
       "9997  201675.9513   451261.801      까페         etc     food  \n",
       "9998  201628.0898  451407.6249      기타         etc     food  \n",
       "9999  200505.1071  451510.4215  통닭(치킨)         etc     food  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729596d9-328c-4944-b470-8be1967295e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "지번주소           0\n",
       "도로명주소          0\n",
       "사업장명           0\n",
       "좌표정보(X)        0\n",
       "좌표정보(Y)        0\n",
       "업태구분명          0\n",
       "category_id    0\n",
       "table_id       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5cf077d-17ed-42dd-b993-49736b5acfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "str_tmp = ''\n",
    "cnt = 0\n",
    "for i, j, k, l in zip(food['사업장명'], food['도로명주소'], food['지번주소'], food['id']):\n",
    "    tmp_dict = {}\n",
    "    tmp_dict1 = {}\n",
    "    if( j != ''):\n",
    "        # str_tmp = i + ' ' + j\n",
    "        tmp_dict1['address'] = j\n",
    "        tmp_dict1['id'] = l\n",
    "        tmp_dict[i] = tmp_dict1\n",
    "        tmp.append(tmp_dict)\n",
    "    elif( k != ''):\n",
    "        # str_tmp = i + ' ' + k\n",
    "        tmp_dict1['address'] = k\n",
    "        tmp_dict1['id'] = l\n",
    "        tmp_dict[i] = tmp_dict1\n",
    "        tmp.append(tmp_dict)\n",
    "    else:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b32c3ae-41d2-425d-96f2-7f7da82c9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#불용어 정의\n",
    "stopwords = ['도', '는', '다','것', '그', '들', '수', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게', '만', '게임','텐데', '겜', '되', '음', '면']\n",
    "stop = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "stoplist = re.split(r'[+ + \\t + \\n]', stop)\n",
    "# stoplist = re.split(r'[가-힣]', stop)\n",
    "# stoplist = re.compile('[가-힣]').findall(stop)\n",
    "for i in range(0, len(stoplist), 3):\n",
    "    stopwords.append(stoplist[i])\n",
    "stopwords= [s for s in stopwords if s != '']\n",
    "\n",
    "# from krwordrank.word import KRWordRank\n",
    "\n",
    "# min_count = 1   # 단어의 최소 출현 빈도수 (그래프 생성 시)\n",
    "# max_length = 10 # 단어의 최대 길이\n",
    "\n",
    "# beta = 0.85   # PageRank의 decaying factor beta\n",
    "# max_iter = 100\n",
    "\n",
    "\n",
    "# from krwordrank.word import summarize_with_keywords\n",
    "\n",
    "# keywords = summarize_with_keywords(texts, min_count=min_count, max_length=max_length,\n",
    "#     beta=beta, max_iter=max_iter, stopwords=stopwords, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ab7a0d9-9b98-451c-a645-416c038c9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_words = pd.read_csv('category.csv',encoding='utf-8')\n",
    "category_words.fillna('', inplace = True)\n",
    "category_keyword = []\n",
    "\n",
    "\n",
    "for category in category_words:\n",
    "    category_tmp = []\n",
    "    category_tmp.append(category)\n",
    "    category_keyword.append(category_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4e9b604-7ab0-4149-936f-7737befaf8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('왔었어요', 0.7433010935783386),\n",
       " ('샀어요', 0.6811431050300598),\n",
       " ('였어요', 0.6549246311187744),\n",
       " ('했었어요', 0.6416402459144592),\n",
       " ('놨어요', 0.6404266953468323),\n",
       " ('했어요', 0.6384304165840149),\n",
       " ('왔어요', 0.6178849339485168),\n",
       " ('어려웠어요', 0.5915448665618896),\n",
       " ('거든요', 0.5608712434768677),\n",
       " ('겠어요', 0.5559830665588379)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastText_model.wv.most_similar('매장이 넓어요')\n",
    "\n",
    "# FastText_model.wv.similarity('신선','청결')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89534847-9e7a-4295-b1e6-507e0bbeaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_classify(method_reviews):\n",
    "\n",
    "    method_texts = method_reviews\n",
    "    review_tmp = ''\n",
    "    review_tmp_list = []\n",
    "\n",
    "    for review in method_texts:\n",
    "        review_tmp = review_tmp + re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', review)\n",
    "        if len(review_tmp) > 500:\n",
    "            review_tmp_list.append(review_tmp)\n",
    "            review_tmp = ''\n",
    "    review_tmp_list.append(review_tmp)\n",
    "\n",
    "    method_texts = []\n",
    "    for review in review_tmp_list:\n",
    "        method_texts.append(text_process(review))\n",
    "\n",
    "\n",
    "    min_count = 1   # 단어의 최소 출현 빈도수 (그래프 생성 시)\n",
    "    max_length = 100 # 단어의 최대 길이\n",
    "\n",
    "    beta = 0.85  # PageRank의 decaying factor beta\n",
    "    max_iter = 10\n",
    "\n",
    "    keywords_tmp = summarize_with_keywords(method_texts, min_count=min_count, max_length=max_length,\n",
    "        beta=beta, max_iter=max_iter, stopwords=stopwords)\n",
    "    \n",
    "    words = sorted(keywords_tmp.items(), key=lambda x:x[1], reverse=True)[:10]\n",
    "    \n",
    "    score = {}\n",
    "    for word in words:\n",
    "        for category in category_keyword:\n",
    "            word_cnt = 0\n",
    "            scores = 0\n",
    "            score_tmp = []\n",
    "            for i in category_words[category[0]]:\n",
    "                if(i != ''):\n",
    "                    score_tmp.append(FastText_model.wv.similarity(word[0], i))\n",
    "                    word_cnt += 1\n",
    "                else:\n",
    "                    score_tmp.append(0)\n",
    "            for k in score_tmp:\n",
    "                scores += k\n",
    "            scores = scores / word_cnt\n",
    "            try:\n",
    "                score[category[0]] += scores\n",
    "            except:\n",
    "                score[category[0]] = scores\n",
    "\n",
    "    for k in score:\n",
    "        score[k] = float(\"{:.4f}\".format(score[k]))\n",
    "\n",
    "    score_list = sorted(score.items(), key=lambda x:x[1], reverse=True)[:7]\n",
    "    \n",
    "    return score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c7b6c57-3a9d-405c-8380-4be0879c6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_category = {'\"혼밥하기 좋아요\"': ['가성비', '맛집', '편안한'],\n",
    "'\"매장이 넓어요\"': ['술집', '청결', '한적', '편안한', '가족', '편리한'],\n",
    "'\"뷰가 좋아요\"' : ['분위기', '청결', '뷰', '기념일', '고급진', '감성적'],\n",
    "'\"단체모임 하기 좋아요\"' : ['가성비', '술집', '분위기', '맛집', '시끌벅적', '활동적', '기념일', '고급진', '가족', '모던한'],\n",
    "'\"인테리어가 멋져요\"' : ['분위기', '청결', '뷰', '기념일', '고급진', '감성적', '모던한', '이국적', '색다른'],\n",
    "'\"가성비가 좋아요\"' : ['가성비', '맛집', '분위기', '편안한'],\n",
    "'\"음식이 맛있어요\"' : ['가성비', '맛집', '가족', '고급진', '청결', '색다른', '이국적'],\n",
    "'\"양이 많아요\"' : ['가성비', '맛집'],\n",
    "'\"재료가 신선해요\"' : ['맛집', '청결', '기념일', '고급진'],\n",
    "'\"특별한 메뉴가 있어요\"' : ['분위기', '맛집', '기념일', '고급진', '전통적', '색다른', '이국적'],\n",
    "'\"친절해요\"' : ['분위기', '맛집', '기념일', '고급진', '감성적', '편안한'],\n",
    "'\"매장이 청결해요\"' : ['청결', '맛집', '한적', '고급진', '모던한'],\n",
    "'\"주차하기 편해요\"': ['한적', '가족', '편리한'],\n",
    "'\"특별한 날 가기 좋아요\"' : ['분위기', '맛집', '청결', '뷰', '기념일', '고급진', '감성적', '가족', '모던한', '색다른'],\n",
    "'\"화장실이 깨끗해요\"' : ['술집', '청결', '고급진', '편리한']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98fcd41b-9353-460f-a2b0-b010562e6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_classify_keywords(method_dict):\n",
    "    dict_sentiment_classify_keywords = []\n",
    "    for senti in method_dict:\n",
    "        insert_dict_tmp = []\n",
    "        try:\n",
    "            method_list_tmp = [senti_category[senti], method_dict[senti] / 500]\n",
    "            dict_sentiment_classify_keywords.append(method_list_tmp)\n",
    "        except:\n",
    "            for method_itr_tmp in sentiment_classify(senti):\n",
    "                insert_dict_tmp.append(method_itr_tmp[0])\n",
    "                \n",
    "            senti_category[senti] = insert_dict_tmp\n",
    "            method_list_tmp = [senti_category[senti], method_dict[senti] / 500]\n",
    "            dict_sentiment_classify_keywords.append(method_list_tmp)\n",
    "    return dict_sentiment_classify_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2243b094-8dc3-4a29-9786-e79ec876ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "    new_sentence = mecab.morphs(new_sentence) # 토큰화\n",
    "    new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "    encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "    pad_new = pad_sequences(encoded, maxlen = 50) # 패딩\n",
    "    score = float(text_model.predict(pad_new, verbose = 0)) # 예측\n",
    "    if(score > 0.3):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "def text_process(text):\n",
    "    m = re.search('ㅋ+|ㅠ+|ㅜ+', text)\n",
    "    if m:\n",
    "        # tmp = spacing(text)\n",
    "        tmp = spell_checker.check(text)[2]\n",
    "        tmp = emoticon_normalize(tmp)\n",
    "        tmp = re.sub('ㅋ+|ㅠ+|ㅜ+', '', tmp)\n",
    "        tmp = repeat_normalize(tmp, num_repeats=1)\n",
    "        return tmp\n",
    "\n",
    "    else :\n",
    "        tmp = text\n",
    "    # tmp = spacing(tmp)\n",
    "    tmp = spell_checker.check(tmp)[2]\n",
    "    return tmp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b430e9d-7818-4d6f-82ce-a09ec4035198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "\n",
    "    def call(self, values, query): # 단, key와 value는 같음\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "    \n",
    "# kargs = {'vocab_size' : vocab_size,\n",
    "#          'max_len': max_len,\n",
    "#          'lstm_size' : 64,\n",
    "#         'dropout_rate' : 0.5,\n",
    "#         'hidden_dimension' : 250,\n",
    "#         'output_dimension' : 1}\n",
    "max_len = 50\n",
    "vocab_size = 42645\n",
    "sequence_input = Input(shape=(max_len,))\n",
    "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len)(sequence_input)\n",
    "\n",
    "lstm = Bidirectional(LSTM(64, dropout=0.5,  return_sequences = True))(embedded_sequences)\n",
    "\n",
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)\n",
    "\n",
    "\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
    "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태\n",
    "\n",
    "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
    "context_vector, attention_weights = attention(lstm, state_h)\n",
    "\n",
    "# hidden = BatchNormalization()(context_vector)\n",
    "# dense1 = Dense(128, activation=\"elu\")(context_vector)\n",
    "# dropout_1 = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(32, activation=\"elu\")(context_vector)\n",
    "dropout_2 = Dropout(0.5)(dense2)\n",
    "# dense3 = Dense(32, activation=\"elu\")(dropout_2)\n",
    "# dropout_3 = Dropout(0.5)(dense3)\n",
    "dense4 = Dense(16, activation=\"elu\")(dropout_2)\n",
    "dropout_4 = Dropout(0.5)(dense4)\n",
    "# dense5 = Dense(8, activation=\"elu\")(dropout_4)\n",
    "# dropout_5 = Dropout(0.5)(dense5)\n",
    "output = Dense(1, activation=\"sigmoid\")(dropout_4)\n",
    "text_model = Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "text_model.compile(loss='binary_crossentropy', optimizer='Nadam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#최적화 과정\n",
    "modelpath = \"./best_model.h5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=2, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "text_model.load_weights('./Model/test_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d020938-9e4d-4b7c-8a81-5d5d1299bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_save(id_check, address, sql_dict_tmp, score, blog_review_cnt):\n",
    "    date_db = pymysql.connect(host='192.168.0.82', port=3306, user='sky6548', passwd='1234', db='datedb', charset='utf8')\n",
    "    cursor = date_db.cursor()\n",
    "    \n",
    "    # na_sql = \"\"\"insert into sentiment(`id`) values( (select id from store where `사업장명` = '{0}' and (`도로명주소` = '{1}' or `지번주소` = '{1}')));\"\"\".format(id_check, address)\n",
    "    na_sql = \"\"\"insert into sentiment(`id`) values( {0} );\"\"\".format(id_check)\n",
    "\n",
    "    cursor.execute(na_sql)\n",
    "\n",
    "    for sql_dict_tmp_key in sql_dict_tmp:\n",
    "        sql_dict_tmp_sql = \"\"\"update sentiment set `{0}` = {1} where `id` = {2};\"\"\".format(sql_dict_tmp_key, sql_dict_tmp[sql_dict_tmp_key], id_check)\n",
    "        cursor.execute(sql_dict_tmp_sql)\n",
    "\n",
    "    score_sql = \"\"\"update sentiment set score = {0}, review_cnt = {1} where `id` = {2};\"\"\".format(score, blog_review_cnt, id_check)\n",
    "    cursor.execute(score_sql)\n",
    "    \n",
    "    date_db.commit()\n",
    "    date_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31b4611d-c59c-4bbf-8452-df10d5d4607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "\n",
    "user_agent= \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"\n",
    "options.add_argument(user_agent)\n",
    "chrome_path = chromedriver_autoinstaller.install()\n",
    "\n",
    "driver= webdriver.Chrome(chrome_path, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66de4af4-f393-42ef-bf6b-185fa8418118",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8608\\3495182977.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrawling_cnt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mcrawling_cnt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mcrawling_cnt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 네이버 지도 검색\n",
    "\n",
    "for all_cnt in range(0, len(tmp)//10000 + 1):\n",
    "    # crawling_list = []\n",
    "    if all_cnt == len(tmp)//10000:\n",
    "        stores = tmp[all_cnt *10000 : len(tmp)]\n",
    "    else:\n",
    "        stores = tmp[all_cnt * 10000 : 10000 + all_cnt * 10000]\n",
    "        \n",
    "    crawling_cnt = 0\n",
    "    \n",
    "    for store in stores:\n",
    "\n",
    "        \n",
    "        store_name_tmp = list(store.keys())[0]\n",
    "        address = store[store_name_tmp]['address']\n",
    "        id_check = store[store_name_tmp]['id']\n",
    "        driver.get(\"https://map.naver.com/\") \n",
    "        driver.implicitly_wait(3)\n",
    "        \n",
    "        if(crawling_cnt > 500):\n",
    "            time.sleep(300)\n",
    "            crawling_cnt=0\n",
    "        crawling_cnt += 1\n",
    "        try:\n",
    "            xpath = \"/html/body/app/layout/div[3]/div[2]/shrinkable-layout/div/app-base/search-input-box/div/div[1]/div/input\"\n",
    "            #검색\n",
    "            search = driver.find_element(By.XPATH,xpath)    \n",
    "            search.send_keys(list(store.values())[0]['address'])\n",
    "            search.send_keys(Keys.ENTER)\n",
    "            driver.implicitly_wait(3)\n",
    "\n",
    "            try:  \n",
    "                xpath = \"/html/body/app/layout/div[3]/div[2]/shrinkable-layout/div/app-base/search-layout/div[2]/entry-layout/entry-address/div/div[2]/div/div[1]/div[3]/div[2]/div/button\"\n",
    "                driver.find_element(By.XPATH,xpath).click()\n",
    "\n",
    "                #더보기\n",
    "                driver.implicitly_wait(3)\n",
    "\n",
    "                try:\n",
    "                    #장소 개수\n",
    "                    xpath = \"/html/body/app/layout/div[3]/div[2]/shrinkable-layout/div/app-base/search-layout/div[2]/entry-layout/entry-address/entry-address-detail-place/div[1]/span\"\n",
    "                    cnt = int(driver.find_element(By.XPATH,xpath).text)\n",
    "                    page = 2\n",
    "                    store_check = True\n",
    "                    \n",
    "                    while(store_check):\n",
    "                        for i in range(1, 21):\n",
    "                            #장소 이름\n",
    "                            xpath = \"/html/body/app/layout/div[3]/div[2]/shrinkable-layout/div/app-base/search-layout/div[2]/entry-layout/entry-address/entry-address-detail-place/div[2]/div/div/div[{0}]/div/div[1]\".format(i)\n",
    "                            str_tmp = driver.find_element(By.XPATH,xpath).text\n",
    "\n",
    "                            store_name = False\n",
    "\n",
    "                            for store_keys_tmp in list(store.keys())[0].split(' '):\n",
    "                                if store_keys_tmp in str_tmp:\n",
    "                                    store_name = True\n",
    "\n",
    "                            if(store_name):\n",
    "                                #장소 리뷰 페이지\n",
    "                                xpath = \"/html/body/app/layout/div[3]/div[2]/shrinkable-layout/div/app-base/search-layout/div[2]/entry-layout/entry-address/entry-address-detail-place/div[2]/div/div/div[{0}]\".format(i)\n",
    "                                driver.find_element(By.XPATH,xpath).click()\n",
    "                                driver.implicitly_wait(3)\n",
    "    \n",
    "\n",
    "                                store_num = driver.current_url.split(\"/place/\")[1].split(\"?c=\")[0]\n",
    "\n",
    "\n",
    "                                review_url = \"https://pcmap.place.naver.com/place/{0}/review\".format(store_num)\n",
    "                                driver.get(review_url) \n",
    "                                driver.implicitly_wait(3)\n",
    "\n",
    "                                #키워드 더보기 선택\n",
    "                                try:\n",
    "                                    more_keyword = \"/html/body/div[3]/div/div/div/div[7]/div[2]/div[1]/div/div/div[2]/a\"\n",
    "                                    tmp_cnt = 1\n",
    "                                    while(True):\n",
    "                                        driver.find_element(By.XPATH,more_keyword).click()\n",
    "                                        more_keyword = \"/html/body/div[3]/div/div/div/div[7]/div[2]/div[1]/div/div/div[2]/a[{0}]\".format(tmp_cnt)\n",
    "                                        tmp_cnt += 1\n",
    "                                        driver.implicitly_wait(1)\n",
    "\n",
    "                                except:\n",
    "                                    pass\n",
    "                                #키워드와 키워드 인원     \n",
    "                                try:\n",
    "                                    tmp_cnt = 1\n",
    "                                    keywords = {}\n",
    "                                    while(True):\n",
    "                                        xpath = \"/html/body/div[3]/div/div/div/div[7]/div[2]/div[1]/div/div/div[2]/ul/li[{0}]/div[2]/span[1]\".format(tmp_cnt)\n",
    "                                        keyword = driver.find_element(By.XPATH,xpath).text\n",
    "\n",
    "                                        xpath = \"/html/body/div[3]/div/div/div/div[7]/div[2]/div[1]/div/div/div[2]/ul/li[{0}]/div[2]/span[2]\".format(tmp_cnt)\n",
    "                                        keyword_cnt = driver.find_element(By.XPATH,xpath).text.split(\"\\n\")[1]\n",
    "                                        keywords[keyword] = int(keyword_cnt)\n",
    "                                        tmp_cnt += 1\n",
    "                                except:\n",
    "                                    pass\n",
    "                                store[list(store.keys())[0]]['keywords'] = keywords\n",
    "\n",
    "\n",
    "                                # 방문자 리뷰\n",
    "                                # 리뷰 더보기\n",
    "                                try:\n",
    "                                    for i in range(0, 15):\n",
    "                                        more_review = \"/html/body/div[3]/div/div/div/div[7]/div[2]/div[3]/div[2]/a\"\n",
    "                                        driver.find_element(By.XPATH,more_review).click()\n",
    "                                        driver.implicitly_wait(1)\n",
    "                                except:\n",
    "                                    pass\n",
    "\n",
    "\n",
    "                                try:\n",
    "                                    reviews = []\n",
    "                                    review = driver.find_elements(By.CLASS_NAME,'xHaT3')\n",
    "                                    for text in review:\n",
    "                                        if len(reviews) > 150:\n",
    "                                            break\n",
    "                                        try:\n",
    "                                            if sentiment_predict(text.text):\n",
    "                                                reviews.append(text.text)\n",
    "                                        except:\n",
    "                                            print('senti error')\n",
    "                                            pass\n",
    "                                except:\n",
    "                                    pass\n",
    "        \n",
    "                             # store[list(store.keys())[0]]['reviews'] = reviews\n",
    "                                keyword_score_list = sentiment_classify_keywords(keywords)\n",
    "                                review_score_list = sentiment_classify(reviews)\n",
    "                                sql_dict_tmp = {}\n",
    "\n",
    "                                for keyword_list_tmp in keyword_score_list:\n",
    "                                    for keywords_list in keyword_list_tmp[0]:\n",
    "                                            try:                                    \n",
    "                                                sql_dict_tmp[keywords_list] = sql_dict_tmp[keywords_list] + keyword_list_tmp[1]\n",
    "                                            except:\n",
    "                                                sql_dict_tmp[keywords_list] = keyword_list_tmp[1]\n",
    "                                                \n",
    "                                for review_score_tmp in review_score_list:\n",
    "                                    try:\n",
    "                                        sql_dict_tmp[review_score_tmp[0]] = sql_dict_tmp[review_score_tmp[0]] + review_score_tmp[1]\n",
    "                                    except:\n",
    "                                        sql_dict_tmp[review_score_tmp[0]] = review_score_tmp[1]\n",
    "                                        \n",
    "                                for sql_dict_tmp_value in sql_dict_tmp:\n",
    "                                    sql_dict_tmp[sql_dict_tmp_value] = float(\"{:.5f}\".format(sql_dict_tmp[sql_dict_tmp_value]))\n",
    "                                    \n",
    "                                score = -1\n",
    "                                try:\n",
    "                                    driver.implicitly_wait(3)\n",
    "                                    xpath = \"/html/body/div[3]/div/div/div/div[2]/div[1]/div[2]/span[1]/em\"\n",
    "                                    score = driver.find_element(By.XPATH,xpath).text\n",
    "                                    store[list(store.keys())[0]]['score'] = float(score)\n",
    "\n",
    "                                except:\n",
    "                                    pass\n",
    "                                store[list(store.keys())[0]]['score'] = score\n",
    "                                \n",
    "                                blog_review_cnt = -1\n",
    "                                #블로그 리뷰\n",
    "                                review_url = \"https://pcmap.place.naver.com/place/{0}/review/ugc?type=photoView\".format(store_num)\n",
    "                                driver.get(review_url) \n",
    "                                driver.implicitly_wait(3)\n",
    "                                \n",
    "                                #블로그 리뷰 갯수\n",
    "                                try:\n",
    "                                    try:\n",
    "                                        xpath = \"/html/body/div[3]/div/div/div/div[7]/div[2]/div/h2/em\"\n",
    "                                        blog_review_cnt = driver.find_element(By.XPATH,xpath).text\n",
    "                                    except:\n",
    "                                        xpath = \"/html/body/div[3]/div/div/div/div[6]/div[2]/div/h2/em\"\n",
    "                                        blog_review_cnt = driver.find_element(By.XPATH,xpath).text\n",
    "                                except:\n",
    "                                    pass\n",
    "                                    \n",
    "                                store[list(store.keys())[0]]['blog_review_cnt'] = blog_review_cnt\n",
    "                                \n",
    "                                # print(id_check, address, sql_dict_tmp, score, blog_review_cnt)\n",
    "                                \n",
    "                                try:\n",
    "                                    sql_save(id_check, address, sql_dict_tmp, score, blog_review_cnt)\n",
    "                                except:\n",
    "                                    pass\n",
    "                                \n",
    "                                #for(1:21) break\n",
    "                                store_check = false\n",
    "                                break\n",
    "\n",
    "                        xpath = \"/html/body/app/layout/div[3]/div[2]/shrinkable-layout/div/app-base/search-layout/div[2]/entry-layout/entry-address/entry-address-detail-place/div[3]/pagination-template/div/a[{0}]\".format(page)\n",
    "                        driver.find_element(By.XPATH,xpath).click()\n",
    "                        page += 1\n",
    "                        driver.implicitly_wait(3)\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "            except:\n",
    "                continue\n",
    "            # crawling_list.append(store)\n",
    "        except:\n",
    "            driver.implicitly_wait(3)\n",
    "    # str_tmp = 'save_' + str(all_cnt) + '.pkl'\n",
    "    # f = open(str_tmp, 'wb')\n",
    "    # pickle.dump(crawling_list, f)\n",
    "    # f.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec6bc1d-7b41-4e96-8271-bd25aa2f28b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open('save.pkl', 'wb')\n",
    "pickle.dump(tmp[0:10], f)\n",
    "f.close()\n",
    "\n",
    "f = open('save.pkl', 'rb')\n",
    "mydict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedde170-89ff-4968-bcd3-380755218564",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7bef0-aa18-47b5-b86f-f9b0971d0e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
